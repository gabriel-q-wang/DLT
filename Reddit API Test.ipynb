{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0541162",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5fa6f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter==1.0.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: numpy==1.20.3 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (1.20.3)\n",
      "Requirement already satisfied: pandas==1.3.2 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: praw==7.4.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (7.4.0)\n",
      "Requirement already satisfied: qtconsole in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: ipywidgets in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (7.6.3)\n",
      "Requirement already satisfied: notebook in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.3)\n",
      "Requirement already satisfied: nbconvert in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.1.0)\n",
      "Requirement already satisfied: jupyter-console in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.4.0)\n",
      "Requirement already satisfied: ipykernel in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter==1.0.0->-r requirements.txt (line 1)) (6.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from pandas==1.3.2->-r requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from pandas==1.3.2->-r requirements.txt (line 3)) (2021.1)\n",
      "Requirement already satisfied: update-checker>=0.18 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from praw==7.4.0->-r requirements.txt (line 4)) (0.18.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from praw==7.4.0->-r requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from praw==7.4.0->-r requirements.txt (line 4)) (1.2.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from prawcore<3,>=2.1->praw==7.4.0->-r requirements.txt (line 4)) (2.26.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.3.2->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw==7.4.0->-r requirements.txt (line 4)) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw==7.4.0->-r requirements.txt (line 4)) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw==7.4.0->-r requirements.txt (line 4)) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw==7.4.0->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (1.4.1)\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (7.27.0)\n",
      "Requirement already satisfied: traitlets<6.0,>=4.1.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (5.0.5)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (7.0.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: argcomplete>=1.12.3 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (1.12.3)\n",
      "Requirement already satisfied: importlib-metadata<5 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (4.8.1)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (6.1)\n",
      "Requirement already satisfied: appnope in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from importlib-metadata<5->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (3.10.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from importlib-metadata<5->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.5)\n",
      "Requirement already satisfied: decorator in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (5.0.9)\n",
      "Requirement already satisfied: pygments in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: backcall in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (4.7.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (22.2.1)\n",
      "Requirement already satisfied: entrypoints in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from pexpect>4.3->ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from traitlets<6.0,>=4.1.0->ipykernel->jupyter==1.0.0->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (5.1.3)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->-r requirements.txt (line 1)) (21.2.0)\n",
      "Requirement already satisfied: jinja2 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (3.0.1)\n",
      "Requirement already satisfied: argon2-cffi in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (21.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.11.1)\n",
      "Requirement already satisfied: prometheus-client in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from jinja2->notebook->jupyter==1.0.0->-r requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (1.4.3)\n",
      "Requirement already satisfied: defusedxml in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.1.2)\n",
      "Requirement already satisfied: bleach in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (4.1.0)\n",
      "Requirement already satisfied: testpath in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.8.4)\n",
      "Requirement already satisfied: packaging in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (21.0)\n",
      "Requirement already satisfied: webencodings in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from packaging->bleach->nbconvert->jupyter==1.0.0->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: qtpy in /Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages (from qtconsole->jupyter==1.0.0->-r requirements.txt (line 1)) (1.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981af1d",
   "metadata": {},
   "source": [
    "## Imports\n",
    "PRAW: https://praw.readthedocs.io/en/stable/code_overview/praw_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66daf243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abbb232",
   "metadata": {},
   "source": [
    "## Create Reddit API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a649a326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_config(config_dict, filename=\"redditConfig.txt\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(config, f)\n",
    "\n",
    "def load_config(filename=\"redditConfig.txt\"):\n",
    "    with open(filename, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4eddcef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<praw.reddit.Reddit at 0x7fc71ad65710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = load_config()\n",
    "reddit = praw.Reddit(**config)\n",
    "reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c0fe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reposts...\n",
      "r/Jokes has a search feature, input the title or punchline of your joke (before posting) and if it's been posted within the last month - please don't submit it.\n",
      "\n",
      "r/jokes has a discord and you need to join!\n",
      "Over 20k members! Come see reposts in real time!\n",
      "\n",
      "https://discord.gg/jokes\n",
      "\n",
      "Can someone please tell me what the lowest rank in the military is?\n",
      "Every time I ask someone they say “it’s private.”\n",
      "\n",
      "A man shouted to his wife, \"Honey, come in here and check out my clock.\"\n",
      "She found him standing naked, with a hard-on. \"That's not a clock!\" she shouted.\n",
      "\n",
      "\"It is,\" he replied. \"It just needs two hands and a face on it.\"\n",
      "\n",
      "What do you call a book club that has been stuck on the same book for years?\n",
      "CHURCH\n",
      "\n",
      "I asked my girlfriend if she was ready for 12 inches of dick and she said yes.\n",
      "I'm so excited for 12 rounds of sex tonight!\n",
      "\n",
      "Recently, a fortune teller told me that in about 12 years I would suffer terrible heartbreak.\n",
      "\n",
      "So,  to cheer myself up, I went and bought a puppy.\n",
      "\n",
      "When you die what part of the body dies last?\n",
      "The pupils because they dilate.\n",
      "\n",
      "How do you know your wife is dead?\n",
      "The sex is the same, but the dishes start piling up.\n",
      "\n",
      "What’s a sex offenders favorite shoes ?\n",
      "White Vans.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "submissions = []\n",
    "for s in reddit.subreddit(\"jokes\").hot(limit=10):\n",
    "    submissions.append(s)\n",
    "    print(s.title)\n",
    "    print(s.selftext)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb62223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Submission(id='ics15s')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submissions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4755fb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>url</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>body</th>\n",
       "      <th>created</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reposts...</td>\n",
       "      <td>4373</td>\n",
       "      <td>ics15s</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/ics15s...</td>\n",
       "      <td>3</td>\n",
       "      <td>r/Jokes has a search feature, input the title ...</td>\n",
       "      <td>1.597858e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r/jokes has a discord and you need to join!</td>\n",
       "      <td>303</td>\n",
       "      <td>pi1gct</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/pi1gct...</td>\n",
       "      <td>71</td>\n",
       "      <td>Over 20k members! Come see reposts in real tim...</td>\n",
       "      <td>1.630796e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>President Biden has announced water is now onl...</td>\n",
       "      <td>4937</td>\n",
       "      <td>qrl3bk</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/qrl3bk...</td>\n",
       "      <td>232</td>\n",
       "      <td>Solid, liquid and gas.</td>\n",
       "      <td>1.636637e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I feel sad for people with gay parents</td>\n",
       "      <td>8363</td>\n",
       "      <td>qrh3ps</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/qrh3ps...</td>\n",
       "      <td>208</td>\n",
       "      <td>They either get twice the number of dad jokes ...</td>\n",
       "      <td>1.636621e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A handsome man in a suit approaches a young la...</td>\n",
       "      <td>971</td>\n",
       "      <td>qrp1he</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/qrp1he...</td>\n",
       "      <td>24</td>\n",
       "      <td>\\n\\nHe looked downcast, \"No, sadly we broke up...</td>\n",
       "      <td>1.636648e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>Yo momma so fat</td>\n",
       "      <td>68</td>\n",
       "      <td>qnyzpv</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/qnyzpv...</td>\n",
       "      <td>19</td>\n",
       "      <td>She only needs a single cup of water to fill u...</td>\n",
       "      <td>1.636201e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>Fast Food Fury</td>\n",
       "      <td>6</td>\n",
       "      <td>qod6dt</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/qod6dt...</td>\n",
       "      <td>0</td>\n",
       "      <td>My fast-food order arrived but it was incomple...</td>\n",
       "      <td>1.636245e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>Mr. Johnson walks into a clinic and says to th...</td>\n",
       "      <td>12</td>\n",
       "      <td>qoadcv</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/qoadcv...</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Are you sure about this?\" asks the doctor. \"I...</td>\n",
       "      <td>1.636236e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>My chemistry teacher offered me a Pb and J san...</td>\n",
       "      <td>3</td>\n",
       "      <td>qof029</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/qof029...</td>\n",
       "      <td>2</td>\n",
       "      <td>Hospital bill is pretty high.</td>\n",
       "      <td>1.636251e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>The bartender yelled at me when I left my stoo...</td>\n",
       "      <td>4</td>\n",
       "      <td>qoenq4</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>https://www.reddit.com/r/Jokes/comments/qoenq4...</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Why did you even bring this in here?!?\" he cr...</td>\n",
       "      <td>1.636250e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>874 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  score      id  \\\n",
       "0                                           Reposts...   4373  ics15s   \n",
       "1          r/jokes has a discord and you need to join!    303  pi1gct   \n",
       "2    President Biden has announced water is now onl...   4937  qrl3bk   \n",
       "3               I feel sad for people with gay parents   8363  qrh3ps   \n",
       "4    A handsome man in a suit approaches a young la...    971  qrp1he   \n",
       "..                                                 ...    ...     ...   \n",
       "869                                    Yo momma so fat     68  qnyzpv   \n",
       "870                                     Fast Food Fury      6  qod6dt   \n",
       "871  Mr. Johnson walks into a clinic and says to th...     12  qoadcv   \n",
       "872  My chemistry teacher offered me a Pb and J san...      3  qof029   \n",
       "873  The bartender yelled at me when I left my stoo...      4  qoenq4   \n",
       "\n",
       "    subreddit                                                url  \\\n",
       "0       Jokes  https://www.reddit.com/r/Jokes/comments/ics15s...   \n",
       "1       Jokes  https://www.reddit.com/r/Jokes/comments/pi1gct...   \n",
       "2       Jokes  https://www.reddit.com/r/Jokes/comments/qrl3bk...   \n",
       "3       Jokes  https://www.reddit.com/r/Jokes/comments/qrh3ps...   \n",
       "4       Jokes  https://www.reddit.com/r/Jokes/comments/qrp1he...   \n",
       "..        ...                                                ...   \n",
       "869     Jokes  https://www.reddit.com/r/Jokes/comments/qnyzpv...   \n",
       "870     Jokes  https://www.reddit.com/r/Jokes/comments/qod6dt...   \n",
       "871     Jokes  https://www.reddit.com/r/Jokes/comments/qoadcv...   \n",
       "872     Jokes  https://www.reddit.com/r/Jokes/comments/qof029...   \n",
       "873     Jokes  https://www.reddit.com/r/Jokes/comments/qoenq4...   \n",
       "\n",
       "     num_comments                                               body  \\\n",
       "0               3  r/Jokes has a search feature, input the title ...   \n",
       "1              71  Over 20k members! Come see reposts in real tim...   \n",
       "2             232                             Solid, liquid and gas.   \n",
       "3             208  They either get twice the number of dad jokes ...   \n",
       "4              24  \\n\\nHe looked downcast, \"No, sadly we broke up...   \n",
       "..            ...                                                ...   \n",
       "869            19  She only needs a single cup of water to fill u...   \n",
       "870             0  My fast-food order arrived but it was incomple...   \n",
       "871             2  \"Are you sure about this?\" asks the doctor. \"I...   \n",
       "872             2                      Hospital bill is pretty high.   \n",
       "873             2  \"Why did you even bring this in here?!?\" he cr...   \n",
       "\n",
       "          created  \n",
       "0    1.597858e+09  \n",
       "1    1.630796e+09  \n",
       "2    1.636637e+09  \n",
       "3    1.636621e+09  \n",
       "4    1.636648e+09  \n",
       "..            ...  \n",
       "869  1.636201e+09  \n",
       "870  1.636245e+09  \n",
       "871  1.636236e+09  \n",
       "872  1.636251e+09  \n",
       "873  1.636250e+09  \n",
       "\n",
       "[874 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "posts = []\n",
    "ml_subreddit = reddit.subreddit('Jokes')\n",
    "for post in ml_subreddit.hot(limit=None):\n",
    "    posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
    "df_jokes = pd.DataFrame(posts,columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\n",
    "df_jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ae31d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi All, I am looking to train a model to suggest tags/categories for a given text string. Have gotten myself totally lost. Hoping someone could suggest a direction to take for the below.\r\n",
      "  \n",
      "\r\n",
      "  \n",
      "eg: \"the fox is weak and limping\" = \\[1-animal\\],\\[34-weak\\],\\[2667-injury\\],\\[16-foot\\] (a list of tags each with probabilities generated by past associations)\r\n",
      "  \n",
      "\r\n",
      "  \n",
      "This data would be trained from a data set of many instances of text each with a corresponding string representing the list of tags that match the text.\r\n",
      "  \n",
      "\r\n",
      "  \n",
      "Is there a way to featurize the text AND the result tags? And apply an algorithm to cross reference them?\r\n",
      "  \n",
      "The closest I have come is the idea of duplicating each of the training data rows so that each row has only one tag at a time.\r\n",
      "  \n",
      "\r\n",
      "  \n",
      "I have been researching this question for a week and am thinking the problem is how I am asking it! Everything I have read does not hint at an existing algorithm to match this use case so should I look towards manipulating the data to a different structure.\r\n",
      "  \n",
      "\r\n",
      "  \n",
      "Any help greatly appreciated.\n",
      "Are data samples for a batch selected randomly?\n",
      "TPU question:\n",
      "\n",
      "I use google colab as well as TPU VMs on GCP for some jax code. The exact same code on the TPU vm is about 10x faster than it is on colab (both using TPU v2-8).\n",
      "\n",
      "Is that a symptom that I'm doing something wrong? Or is colab just slow?\n",
      "I have two sets of biographies, one from clients who speak Spanish and another from clients who only speak English, now I want to do my machine learning so that it automatically classifies the biographies of people who possibly speak Spanish, I think I already have the code but no I know how to run it, I'm sad haha, I think this is not my thing, I'm also looking for a mentor for wich I can work for free.\n",
      "Where would I start to create something that can process audio in real time? The vague idea is voice morphing, specifically a male voice to a female voice, so pitch shifting and filtering the voice to remove the tell-tale audio 'signature' that all currently available voice morphing programs are unable to get rid of.\n",
      "What is the easiest way to replace a large number of zero values in a dataset with the mean of all other instances of that class?\n",
      "Hi all\n",
      "\n",
      "Very new to this subreddit so apologies if the question isn’t appropriate. \n",
      "\n",
      "I have a good education background where I have studied a lot of programming/IT but mostly specialised un mathematics. I have a job that requires a lot of math applied nowadays. \n",
      "\n",
      "I’ve studied a bit of machine learning back in school. I would want to start learning about this again. Would you be able to point me to the relevant resources?\n",
      "\n",
      "I’m not afraid of the math concepts as I believe I have a background that should help me fight it but my knowledge of ML is probably around beginner/intermediate (and what I know I probably need to relearn anyway). \n",
      "\n",
      "I did the Coursera ML class 2 years back which I found interesting but, and I hope it wouldn’t be an offense to anyone, the level was fairly beginner. I don’t mean to brag off, I just want to find the most appropriate course for me. \n",
      "\n",
      "Thank you for you help in advance\n",
      "I've a simple text classification model and tf-idf + xgboost is performing better than tf-idf and feed forward neural network. How can I improve the accuracy of neutral network model?\n",
      "Is there any special trick to transfer learning, or can I just add some predicted outputs of model A to the input vectors of model B (along with its original raw data)?\n",
      "Hello!  I'm looking to scrape information from a bunch of youtube videos, including title, likes/dislikes, views, possibly thumbnail, date, etc.  I would need to scrape and sample thousands of videos, and ideally there'd be a good diversity of content/from various genres.  \n",
      "Does anyone have any ideas about ways to approach this?  Any tutorial or walkthrough would be super helpful!\n",
      "I am trying to do basic image processing. I have a 8k image when I try to open tha image using tkinter canvas I can only see a part of the image( image is adjusted to my 2k screen) Is there a way to see the full 8k image without resizing it. If I resize the image there is huge drop in quality. Is there any other way?\n",
      "I plan to train a deep network that has two branches, one for video image and the second one for sequential data, later the output of both branches is merge thru concatenation and pass thru a fully conected network, then lstm for final prediction. I am wondering is it possible to train the model with both input data but later if needed remove one side, i.e. the video images. an only predict with sequential data?\n",
      "\n",
      "or if someone knows about any paper to start looking at i just dont know how to approach this. or if it is even possible (which sounds like not)\n",
      "Looking for advice of what ML or NN technics to use for showing faces before-mid-after having a lot of photos from makeup master. So that there are initial images, couple of in progress and final. Imagine scroll bar that will predict no makeup to final beauty of taken face photo.\n",
      "Thanks!\n",
      "Can someone recommend platforms like VISxAI ([https://visxai.io/](https://visxai.io/)) for submitting visualizable explainables for topics in Machine Learning?\n",
      "Suppose I create a recommendation system and deploy the model as an api. The api takes a product id as input and output a a list of related products ids.\n",
      "\n",
      "Question: How do I display the recommended products with accurate price data, and remove any that have gone out of stock?  Is this typically the work of the web devs or is it something I should build into my recommend API?\n",
      "Not sure if this is allowed here\n",
      "\n",
      "I can choose either taking information theory or linear network optimization next semester in my university. Which one is more relevant to (theoritical) machine learning?\n",
      "Hi - I'm a UX writer working at a company utilizing Ai and machine learning. Are there new and noteworthy happenings to do with writing copy and content utilizing/for machine learning?\n",
      "Hi, I'm looking to use Single Spectrum Analysis (SSA) as a Time Series Forecasting technique which has quite a few papers describing its accuracy with chaotic/nonlinear and volatile data. It's also easy to implement.\n",
      "\n",
      "I will use BTC daily prices since I don't want to engage in intraday trading but rather to extract a bullish/bearish signal.\n",
      "\n",
      "A higher predicted closing price is de facto a bullish signal but I've seen people do some preprocessing on their input data like taking its logarithm, or taking a ratio of the price to the volume, and then taking its logarithm.\n",
      "\n",
      "I'm kind of stumped as to which direction to go with my data. Should I preprocess it? Or just go with the closing price.\n",
      "\n",
      "Maybe SSA will be able to make better predictions of the price percent change rather than the price itself?\n",
      "Hello Learners , i was going through the paper [Two-Stage Model-Agnostic Meta-LearningWith Noise Mechanism for One-Shot Imitation](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwjk-9aqi470AhVywTgGHXvQCq4QFnoECAMQAQ&url=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F346117785_Two-Stage_Model-Agnostic_Meta-Learning_With_Noise_Mechanism_for_One-Shot_Imitation&usg=AOvVaw1y0oQjD29kmT0sizUgPi_Q) . And i have a doubt i hope somebody will help me to clarify my simple doubt .\n",
      "\n",
      "So why in MODEL-AGNOSTIC META-LEARNING FOR ONE-SHOTIMITATION Algorithm In the inner gradient update phase, we only provide visualinformation to the model without expert actions, and the innerloss is calculated as a function of the output , without considering it's actual labels . why is this?\n",
      "What is the difference between MSE ( Mean Squared Error) and MSPE (Mean Squared Prediction Error) ? Do we use MSPE for classification and MSE for regression? Can someone with experience please elaborate with example?\n",
      "I don’t understand this Reddit. I can’t post anything that’s a question or link.\n",
      "Hi i want to ask if someone with experince about ai in medical diagnosis can help  to list current applications off ml and ai in diagnosis \n",
      "Iam a node backend developer\n",
      "I intend to create a web app project that relates to \n",
      "Ai and machine learning \n",
      "Thanks.\n",
      "What would be an appropriate model for matching two data sets - for example Item A is compatible with Product A? Super simple model as only testing.\n",
      "Can someone point me to a concise tutorial on how to actually get started? With an M1 Mac in mind? I just cannot find a setup tutorial that works.\n",
      "Hi, can someone please help me to download dataset from AWS ?\n",
      "Does google have free access to whatever data I upload for my own project? \n",
      "\n",
      "I’m doing some small projects with a data set that may not be completely free to public access. As in, it needs some special application to have an access to that data set. I was thinking of using google colab for processing, but then I realized that if it’s on google server, they may have access to it even without my consent. Is that true?\n",
      "Hey I am new into the topic of machine learning\n",
      "I am tryin do make a classifier with Ensemble Methods\n",
      "What are the best Attributes for measuring the reliability?\n",
      "Is a good accuracy, sensitifity and specifity enough?\n",
      "1. you can do what you suggested - e.g. if you have 2500 tags, train 2500 different models\n",
      "2. If your main model is a neural network, you can train just one model, with 2500 output shape, and the last layer having sigmoid activations. This way, it can predict multiple tags for each text. If you do that, I'd recommend playing around with the thresholds for predicting rarer tags - if e.g. the animal tag is present in 1% of the train dataset, and you are using 0.5 threshold, the model might never be confident enough to predict \"animal\". You might then lower the \"animal\" threshold to 0.1. \n",
      "3. [https://github.com/dmlc/xgboost/issues/3439](https://github.com/dmlc/xgboost/issues/3439) \\- take a look here, you might find something useful.\n",
      "One reasonable (though pretty modern) scheme would be to get a sentence vector for each of your original sentences (eg: [USE by Google](https://www.tensorflow.org/hub/tutorials/semantic_similarity_with_tf_hub_universal_encoder)), and then create embedding vectors for each of the classes that you mention (i.e. 3000 different vectors, each with the same length as the USE output, initialised randomly).\n",
      "\n",
      "Training would be \\*contrastive\\* : For all the sentences (fixed embeddings), if the class tag is positive (i.e. present) then class embedding vector should be closer, for all the other tags (negatives), further away.  Iterate : Consider using a Margin Loss.\n",
      "\n",
      "Once trained, you will be able to just do a cosine similarity of all the tags vs the (new) sentence, and see which ones are close.\n",
      "During training, it is very common (basically always) to have the data points of the batch picked \"randomly\" . However, data points that were used already through this epoch are not re-processed. In other words, you go through all samples few at the times, picking randomly.\n",
      "\n",
      "&#x200B;\n",
      "\n",
      "For validation and testing batches, this is typically not the case (since you don't take any gradient steps, there's no use in randomizing batches).\n",
      "For the data pipeline, you'll typically have a component that creates the batches from the individual data items.  There'll probably be something to do with shuffle-ing of data.\n",
      "\n",
      "For instance : [PyTorch DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) or [TensorFlow dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle)\n",
      "\n",
      "(BrianP21 said the right stuff w.r.t training/validation/test).\n",
      "Sorry, but your working for free has zero value right now. On the other hand, there are plenty of tutorials and courses online. Try Andrew Ng's course in coursera.\n",
      "Probably: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html (gives you more flexibility than just using the mean as well)\n",
      "You can try the Machine learning course by Stanford University and after that, you can start with specialized fields.\n",
      "\n",
      "You can check this link\n",
      "(https://online.stanford.edu/programs/artificial-intelligence-graduate-program)\n",
      "You can do word2vec encodings instead of tf-idf. You can also replace the MLP with e.g. LSTM or some other architecture. After you do that, you can start looking [here](https://paperswithcode.com/task/text-classification) , choose a dataset that is similar to what you have (number of classes, subject, size, difficulty), and pick a repo that is easy to retrain on your data. If your dataset is small-ish, you can think of doing transfer learning - taking a pre-trained model, and only retraining the last few layers.   \n",
      "\n",
      "\n",
      "tfidf + xgboost is a strong baseline though, don't expect ultra dramatic improvements.\n",
      "I would suggest information theory, but I’m biased by my own interests. They are both relevant to theoretical machine learning, but in two different areas of the theory\n",
      "Linear network optimization is a lot more specific. Info theory will likely provide you with more applicable knowledge\n",
      "After a quick google search (never hear of MSPE before), it looks like difference is between whether you’re measuring a predictor vs estimator. Just use MSE. \n",
      "\n",
      "Also, it seems like you need a better understanding of classification vs regression, as this kind of eval metric would not be useful at all for a classification problem\n",
      "Thank you. Will look into it\n",
      "Thanks mate !! Yeah so I actually have a fair amount of idea wrt Classification, Regression ML methods and their application.\n",
      "\n",
      "As you said, evaluation criteria is something I've to look into.\n"
     ]
    }
   ],
   "source": [
    "submission = reddit.submission(id=df_posts.loc[0]['id'])\n",
    "submission.comments.replace_more(limit=0)\n",
    "for top_level_comment in submission.comments.list():\n",
    "    print(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac147b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Submission(id='qorekl')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "213811ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.upvote_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3231e1",
   "metadata": {},
   "source": [
    "## Submission object atributes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf7a6f",
   "metadata": {},
   "source": [
    "| Attribute              | Description                                                                             |\n",
    "|:-----------------------|:----------------------------------------------------------------------------------------|\n",
    "| author                 | Provides an instance of Redditor.                                                       |\n",
    "| clicked                | Whether or not the submission has been clicked by the client.                           |\n",
    "| comments               | Provides an instance of CommentForest.                                                  |\n",
    "| created_utc            | Time the submission was created, represented in Unix Time.                              |\n",
    "| distinguished          | Whether or not the submission is distinguished.                                         |\n",
    "| edited                 | Whether or not the submission has been edited.                                          |\n",
    "| id                     | ID of the submission.                                                                   |\n",
    "| is_original_content    | Whether or not the submission has been set as original content.                         |\n",
    "| is_self                | Whether or not the submission is a selfpost (text-only).                                |\n",
    "| link_flair_template_id | The link flair’s ID.                                                                    |\n",
    "| link_flair_text        | The link flair’s text content, or None if not flaired.                                  |\n",
    "| locked                 | Whether or not the submission has been locked.                                          |\n",
    "| name                   | Fullname of the submission.                                                             |\n",
    "| num_comments           | The number of comments on the submission.                                               |\n",
    "| over_18                | Whether or not the submission has been marked as NSFW.                                  |\n",
    "| permalink              | A permalink for the submission.                                                         |\n",
    "| poll_data              | A PollData object representing the data of this submission, if it is a poll submission. |\n",
    "| saved                  | Whether or not the submission is saved.                                                 |\n",
    "| score                  | The number of upvotes for the submission.                                               |\n",
    "| selftext               | The submissions’ selftext - an empty string if a link post.                             |\n",
    "| spoiler                | Whether or not the submission has been marked as a spoiler.                             |\n",
    "| stickied               | Whether or not the submission is stickied.                                              |\n",
    "| subreddit              | Provides an instance of Subreddit.                                                      |\n",
    "| title                  | The title of the submission.                                                            |\n",
    "| upvote_ratio           | The percentage of upvotes from all votes on the submission.                             |\n",
    "| url                    | The URL the submission links to, or the permalink if a selfpost.                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41087dfa",
   "metadata": {},
   "source": [
    "## Comment Object Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f87e4e",
   "metadata": {},
   "source": [
    "| author        | Provides an instance of Redditor.                                                                                                           |\n",
    "|---------------|---------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| body          | The body of the comment, as Markdown.                                                                                                       |\n",
    "| body_html     | The body of the comment, as HTML.                                                                                                           |\n",
    "| created_utc   | Time the comment was created, represented in Unix Time.                                                                                     |\n",
    "| distinguished | Whether or not the comment is distinguished.                                                                                                |\n",
    "| edited        | Whether or not the comment has been edited.                                                                                                 |\n",
    "| id            | The ID of the comment.                                                                                                                      |\n",
    "| is_submitter  | Whether or not the comment author is also the author of the submission.                                                                     |\n",
    "| link_id       | The submission ID that the comment belongs to.                                                                                              |\n",
    "| parent_id     | The ID of the parent comment (prefixed with t1_). If it is a top-level comment, this returns the submission ID instead (prefixed with t3_). |\n",
    "| permalink     | A permalink for the comment. Comment objects from the inbox have a context attribute instead.                                               |\n",
    "| replies       | Provides an instance of CommentForest.                                                                                                      |\n",
    "| saved         | Whether or not the comment is saved.                                                                                                        |\n",
    "| score         | The number of upvotes for the comment.                                                                                                      |\n",
    "| stickied      | Whether or not the comment is stickied.                                                                                                     |\n",
    "| submission    | Provides an instance of Submission. The submission that the comment belongs to.                                                             |\n",
    "| subreddit     | Provides an instance of Subreddit. The subreddit that the comment belongs to.                                                               |\n",
    "| subreddit_id  | The subreddit ID that the comment belongs to.                                                                                               |\n",
    "| saved         | Whether or not the submission is saved.                                                                                                     |\n",
    "| score         | The number of upvotes for the submission.                                                                                                   |\n",
    "| selftext      | The submissions’ selftext - an empty string if a link post.                                                                                 |\n",
    "| spoiler       | Whether or not the submission has been marked as a spoiler.                                                                                 |\n",
    "| stickied      | Whether or not the submission is stickied.                                                                                                  |\n",
    "| subreddit     | Provides an instance of Subreddit.                                                                                                          |\n",
    "| title         | The title of the submission.                                                                                                                |\n",
    "| upvote_ratio  | The percentage of upvotes from all votes on the submission.                                                                                 |\n",
    "| url           | The URL the submission links to, or the permalink if a selfpost.                                                                            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7133a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:pmaw.PushshiftAPIBase:Not all PushShift shards are active. Query results may be incomplete.\n",
      "INFO:pmaw.PushshiftAPIBase:Total:: Success Rate: 100.00% - Requests: 1 - Batches: 1 - Items Remaining: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pmaw import PushshiftAPI\n",
    "\n",
    "api = PushshiftAPI()\n",
    "\n",
    "submissions = api.search_submissions(subreddit=\"jokes\", limit=100)\n",
    "\n",
    "sub_df = pd.DataFrame(submissions)\n",
    "\n",
    "sub_df.to_csv('jokes_100.csv', header=True, index=False, columns=list(sub_df.axes[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b02479d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_awardings',\n",
       " 'allow_live_comments',\n",
       " 'author',\n",
       " 'author_flair_css_class',\n",
       " 'author_flair_richtext',\n",
       " 'author_flair_text',\n",
       " 'author_flair_type',\n",
       " 'author_fullname',\n",
       " 'author_patreon_flair',\n",
       " 'author_premium',\n",
       " 'awarders',\n",
       " 'can_mod_post',\n",
       " 'contest_mode',\n",
       " 'created_utc',\n",
       " 'domain',\n",
       " 'full_link',\n",
       " 'gildings',\n",
       " 'id',\n",
       " 'is_crosspostable',\n",
       " 'is_meta',\n",
       " 'is_original_content',\n",
       " 'is_reddit_media_domain',\n",
       " 'is_robot_indexable',\n",
       " 'is_self',\n",
       " 'is_video',\n",
       " 'link_flair_background_color',\n",
       " 'link_flair_richtext',\n",
       " 'link_flair_text_color',\n",
       " 'link_flair_type',\n",
       " 'locked',\n",
       " 'media_only',\n",
       " 'no_follow',\n",
       " 'num_comments',\n",
       " 'num_crossposts',\n",
       " 'over_18',\n",
       " 'parent_whitelist_status',\n",
       " 'permalink',\n",
       " 'pinned',\n",
       " 'pwls',\n",
       " 'retrieved_on',\n",
       " 'score',\n",
       " 'selftext',\n",
       " 'send_replies',\n",
       " 'spoiler',\n",
       " 'stickied',\n",
       " 'subreddit',\n",
       " 'subreddit_id',\n",
       " 'subreddit_subscribers',\n",
       " 'subreddit_type',\n",
       " 'thumbnail',\n",
       " 'title',\n",
       " 'total_awards_received',\n",
       " 'treatment_tags',\n",
       " 'upvote_ratio',\n",
       " 'url',\n",
       " 'whitelist_status',\n",
       " 'wls',\n",
       " 'removed_by_category',\n",
       " 'link_flair_css_class',\n",
       " 'link_flair_text']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sub_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f43022bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patrickc410/miniconda3/envs/dlt_env/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (70,71) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/jokes_10000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f6ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404c4c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Widow is just the right amount of hot.</td>\n",
       "      <td>In other words, Natasha Warm Enough.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What did pilot in 1943 say when drop the bomb</td>\n",
       "      <td>Dam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many cannibals does it take to screw in on...</td>\n",
       "      <td>I have no clue but you really shouldn't be in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is an orange pith?</td>\n",
       "      <td>It's what you get when you drink too much oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why did Marx write all his letters in lowercase?</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0       Black Widow is just the right amount of hot.   \n",
       "1      What did pilot in 1943 say when drop the bomb   \n",
       "2  How many cannibals does it take to screw in on...   \n",
       "3                            What is an orange pith?   \n",
       "4   Why did Marx write all his letters in lowercase?   \n",
       "\n",
       "                                            selftext  \n",
       "0               In other words, Natasha Warm Enough.  \n",
       "1                                                Dam  \n",
       "2  I have no clue but you really shouldn't be in ...  \n",
       "3  It's what you get when you drink too much oran...  \n",
       "4                                          [removed]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text = df[[\"title\", \"selftext\"]]\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16227aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Black Widow is just the right amount of hot.</td>\n",
       "      <td>In other words, Natasha Warm Enough.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What did pilot in 1943 say when drop the bomb</td>\n",
       "      <td>Dam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How many cannibals does it take to screw in on...</td>\n",
       "      <td>I have no clue but you really shouldn't be in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is an orange pith?</td>\n",
       "      <td>It's what you get when you drink too much oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I scored extremely well on my socialist exam l...</td>\n",
       "      <td>I got top Marx.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0       Black Widow is just the right amount of hot.   \n",
       "1      What did pilot in 1943 say when drop the bomb   \n",
       "2  How many cannibals does it take to screw in on...   \n",
       "3                            What is an orange pith?   \n",
       "6  I scored extremely well on my socialist exam l...   \n",
       "\n",
       "                                            selftext  \n",
       "0               In other words, Natasha Warm Enough.  \n",
       "1                                                Dam  \n",
       "2  I have no clue but you really shouldn't be in ...  \n",
       "3  It's what you get when you drink too much oran...  \n",
       "6                                    I got top Marx.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered = df_text[df_text.selftext != \"[removed]\"]\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c61edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(\"data/jokes_10000.txt\", sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c462001f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(df.id).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "251f7028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       m0yj7y\n",
       "1       m0yg6o\n",
       "2       m0yfn1\n",
       "3       m0yfk9\n",
       "4       m0ydp2\n",
       "         ...  \n",
       "9995    miiu6w\n",
       "9996    miiqnw\n",
       "9997    miilil\n",
       "9998    ml68yg\n",
       "9999    ml68m1\n",
       "Name: id, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb893782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['YES', 'm0yj7y', 'm0yg6o', ..., 'miilil', 'ml68yg', 'ml68m1'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "ids_list = np.array([\"YES\"])\n",
    "new_ids_list = np.concatenate((ids_list, df.id.to_numpy()))\n",
    "new_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c960b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['all_awardings',\n",
       " 'allow_live_comments',\n",
       " 'author',\n",
       " 'awarders',\n",
       " 'can_mod_post',\n",
       " 'contest_mode',\n",
       " 'created_utc',\n",
       " 'domain',\n",
       " 'full_link',\n",
       " 'gildings',\n",
       " 'id',\n",
       " 'is_crosspostable',\n",
       " 'is_meta',\n",
       " 'is_original_content',\n",
       " 'is_reddit_media_domain',\n",
       " 'is_robot_indexable',\n",
       " 'is_self',\n",
       " 'is_video',\n",
       " 'link_flair_richtext',\n",
       " 'link_flair_text_color',\n",
       " 'link_flair_type',\n",
       " 'locked',\n",
       " 'media_only',\n",
       " 'no_follow',\n",
       " 'num_comments',\n",
       " 'num_crossposts',\n",
       " 'over_18',\n",
       " 'parent_whitelist_status',\n",
       " 'permalink',\n",
       " 'pinned',\n",
       " 'pwls',\n",
       " 'retrieved_on',\n",
       " 'score',\n",
       " 'send_replies',\n",
       " 'spoiler',\n",
       " 'stickied',\n",
       " 'subreddit',\n",
       " 'subreddit_id',\n",
       " 'subreddit_subscribers',\n",
       " 'subreddit_type',\n",
       " 'thumbnail',\n",
       " 'title',\n",
       " 'total_awards_received',\n",
       " 'treatment_tags',\n",
       " 'upvote_ratio',\n",
       " 'url',\n",
       " 'whitelist_status',\n",
       " 'wls']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.dropna(axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61b18b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmaw import PushshiftAPI\n",
    "import praw\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6f5e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_praw_config(config_dict, filename=\"redditConfig.txt\"):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(config, f)\n",
    "\n",
    "def load_praw_config(filename=\"redditConfig.txt\"):\n",
    "    with open(filename, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "class PMAWRedditPull:\n",
    "    def __init__(self prawEnrichment=None):\n",
    "        self.prawEnrichment = prawEnrichment\n",
    "        self.api = self.init_pushshift_conn(self.prawEnrichment)\n",
    "        self.ids_list = np.array([])\n",
    "\n",
    "    def init_pushshift_conn(self, prawEnrichment):\n",
    "        if prawEnrichment:\n",
    "            return PushshiftAPI(praw=prawEnrichment)\n",
    "        return api = PushshiftAPI()\n",
    "\n",
    "    def filter_unique(self, item):\n",
    "        return item[\"id\"] not in self.ids_list\n",
    "\n",
    "    def pull_subreddit(self, sub, limit, filter_fn=None):\n",
    "        if filter_fn:\n",
    "            return api.search_submissions(subreddit=sub, limit=limit, filter_fn=filter_fn)\n",
    "        return api.search_submissions(subreddit=sub, limit=limit)\n",
    "\n",
    "    def write_submissions_to_csv(self, submissions, outfile):\n",
    "        df_sub = pd.DataFrame(submissions)\n",
    "        df_sub.to_csv(outfile, header=True, index=False, columns=list(sub_df.axes[1]))\n",
    "        print(f\"wrote dataframe of shape '{df_sub.shape}' to file: '{outfile}'\")\n",
    "        return df_sub.id.to_numpy()\n",
    "    \n",
    "    \n",
    "    def pull_sub_chunks(self, chunk_size, sub, limit, outfile_root, filter_fn=None):\n",
    "        \n",
    "        frag_index = 0\n",
    "        index = 0\n",
    "        \n",
    "        while index < limit:\n",
    "            done = False\n",
    "            while not done:\n",
    "                try:\n",
    "                    submissions = self.pull_subreddit(sub, chunksize, filter_fn)\n",
    "                    done = True\n",
    "                except Exception as e:\n",
    "                    print(f\"error on frag_index {frag_index}, index {index}: {e}\")\n",
    "            \n",
    "            new_ids = self.write_submissions_to_csv(submissions, f\"{outfile_root}_frag{frag_index}.csv\")\n",
    "            self.ids_list = np.concatenate((self.ids_list, new_ids))\n",
    "            print(f\"total number of submission ids acquired: {self.ids_list}\")\n",
    "            print(f\"frag_index {frag_index}, index: {index}, done with {round(index/limit, 4) * 100}%\\n--------------\")\n",
    "\n",
    "            frag_index += 1\n",
    "            index += chunk_size\n",
    "        \n",
    "        print(\"DONE\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
